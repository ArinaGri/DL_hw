{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAmPJkRQoyTP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import random\n",
        "import torch.optim as optim\n",
        "import albumentations as A\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torch\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import copy\n",
        "import torch.nn as nn\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJagilTijbUk"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxr_eDvxtQV6"
      },
      "outputs": [],
      "source": [
        "p = '/content/drive/MyDrive/DL'\n",
        "os.listdir(p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7PN9WLpl3FF"
      },
      "outputs": [],
      "source": [
        "path_df ='/content/drive/MyDrive/DL/dl-2025-competition-1.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfopIAT-mfbU"
      },
      "outputs": [],
      "source": [
        "#with zipfile.ZipFile(path_df, 'r') as zr:\n",
        "#    zr.extractall('/content/drive/MyDrive/DL/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VcRdHPBsZQs"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/DL/dl-2025-competition-1/data'\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "\n",
        "classes = os.listdir(train_dir)\n",
        "num_classes = len(classes)\n",
        "\n",
        "train_counts = {}\n",
        "for cls in classes:\n",
        "    train_counts[cls] = len(os.listdir(os.path.join(train_dir, cls)))\n",
        "\n",
        "count_df = pd.DataFrame({\n",
        "    'Class': classes,\n",
        "    'Train Samples': [train_counts[cls] for cls in classes]\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvfXsPWl65f_"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15, 8))\n",
        "ax = sns.barplot(data=count_df.sort_values('Train Samples', ascending=False),\n",
        "                 x='Class',\n",
        "                 y='Train Samples',\n",
        "    hue='Class', palette='viridis')\n",
        "plt.title('Распределение изображений по классам', fontsize=16)\n",
        "plt.xlabel('Классы', fontsize=14)\n",
        "plt.ylabel('Количество изображений', fontsize=14)\n",
        "plt.xticks(rotation=90)\n",
        "ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BB8uxqUFij7s"
      },
      "outputs": [],
      "source": [
        "count_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okSVbOHyi7Ch"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "sns.boxplot(x=count_df['Train Samples'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJsSqes2zzfb"
      },
      "outputs": [],
      "source": [
        "classes_img = sorted(os.listdir(train_dir))[:10]\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15, 8))\n",
        "for i, cls in enumerate(classes_img):\n",
        "    class_images = os.listdir(os.path.join(train_dir, cls))\n",
        "    img_name = random.choice(class_images)\n",
        "    img_path = os.path.join(train_dir, cls, img_name)\n",
        "\n",
        "    try:\n",
        "        img = Image.open(img_path)\n",
        "        plt.subplot(2, 5, i+1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f'Class: {cls}')\n",
        "        plt.axis('off')\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {img_path}: {e}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dGJG92P5OL0"
      },
      "outputs": [],
      "source": [
        "sizes = []\n",
        "for cls in classes[:10]:\n",
        "    for img_name in os.listdir(os.path.join(train_dir, cls)):\n",
        "        img_path = os.path.join(train_dir, cls, img_name)\n",
        "        sizes.append(Image.open(img_path).size)\n",
        "\n",
        "\n",
        "sizes = np.array(sizes)\n",
        "\n",
        "\n",
        "print(f\"Average width: {np.mean(sizes[:, 0]):.1f} ± {np.std(sizes[:, 0]):.1f}\")\n",
        "print(f\"Average height: {np.mean(sizes[:, 1]):.1f} ± {np.std(sizes[:, 1]):.1f}\")\n",
        "print(f\"Min size: {sizes.min(axis=0)}\")\n",
        "print(f\"Max size: {sizes.max(axis=0)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ts29O_XvmspK"
      },
      "outputs": [],
      "source": [
        "# def compute_mean_std_fast(dataset_path, max_samples=10000):\n",
        "#     pixel_sum = np.zeros(3)\n",
        "#     pixel_sq_sum = np.zeros(3)\n",
        "#     count = 0\n",
        "\n",
        "#     class_folders = os.listdir(dataset_path)\n",
        "#     np.random.shuffle(class_folders)\n",
        "\n",
        "#     for class_folder in tqdm(class_folders, desc=\"Processing classes\"):\n",
        "#         if count >= max_samples:\n",
        "#             break\n",
        "\n",
        "#         class_path = os.path.join(dataset_path, class_folder)\n",
        "#         if not os.path.isdir(class_path):\n",
        "#             continue\n",
        "\n",
        "#         img_names = os.listdir(class_path)\n",
        "#         np.random.shuffle(img_names)\n",
        "\n",
        "#         for img_name in img_names:\n",
        "#             if count >= max_samples:\n",
        "#                 break\n",
        "\n",
        "#             img_path = os.path.join(class_path, img_name)\n",
        "#             try:\n",
        "#                 img = Image.open(img_path).convert('RGB')\n",
        "#                 img_array = np.array(img) / 255.0\n",
        "#                 pixel_sum += img_array.mean(axis=(0, 1))\n",
        "#                 pixel_sq_sum += (img_array**2).mean(axis=(0, 1))\n",
        "#                 count += 1\n",
        "#             except:\n",
        "#                 continue\n",
        "\n",
        "#     mean = pixel_sum / count\n",
        "#     std = np.sqrt(pixel_sq_sum / count - mean**2)\n",
        "\n",
        "#     return mean, std\n",
        "\n",
        "# compute_mean_std_fast(train_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzrv9fBItRdd"
      },
      "source": [
        "(array([0.50691125, 0.48691937, 0.44028778]),\n",
        " array([0.2668507 , 0.25536751, 0.27503409]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rllchLHDk2nN"
      },
      "outputs": [],
      "source": [
        "mean = [0.50691125, 0.48691937, 0.44028778]\n",
        "std = [0.2668507, 0.25536751, 0.27503409]\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.VerticalFlip(p=0.5),\n",
        "    A.Rotate(limit=15, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "test_transform = A.Compose([\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHvnSrBElDYC"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = sorted(os.listdir(root_dir))\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        self.images = []\n",
        "\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(root_dir, cls)\n",
        "            for img_name in os.listdir(cls_dir):\n",
        "                self.images.append((os.path.join(cls_dir, img_name), self.class_to_idx[cls]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.images[idx]\n",
        "        image = np.array(Image.open(img_path).convert('RGB'))\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0M7yU9blzmP"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(train_dir, transform=train_transform)\n",
        "\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "om3JOXWnoz-0"
      },
      "outputs": [],
      "source": [
        "def denormalize_image(tensor):\n",
        "    return tensor.clone()\n",
        "\n",
        "def show_batch_images(dataloader, num_images=32, nrow=8, figsize=(12, 6)):\n",
        "    images, labels = next(iter(dataloader))\n",
        "    images = images[:num_images]\n",
        "    img_grid = torchvision.utils.make_grid(\n",
        "        denormalize_image(images),\n",
        "        nrow=nrow,\n",
        "        padding=2,\n",
        "        normalize=False\n",
        "    )\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(img_grid.permute(1, 2, 0))\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "show_batch_images(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUDUg7LgmJUV"
      },
      "outputs": [],
      "source": [
        "class AdvancedDataset(Dataset):\n",
        "    def __init__(self, samples, transform=None, upscale=False, cache=True):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            samples: список кортежей (путь_к_изображению, метка)\n",
        "            transform: albumentations трансформации\n",
        "            upscale: увеличивать ли изображения\n",
        "            cache: кэшировать ли изображения в памяти\n",
        "        \"\"\"\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "        self.upscale = upscale\n",
        "        self.cache = cache\n",
        "        self.image_cache = {}\n",
        "\n",
        "        # Получаем уникальные классы из samples\n",
        "        self.classes = sorted(list(set([label for _, label in samples])))\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "\n",
        "    def _load_image(self, path):\n",
        "        if self.cache and path in self.image_cache:\n",
        "            return self.image_cache[path]\n",
        "\n",
        "        image = Image.open(path).convert('RGB')\n",
        "        if self.upscale:\n",
        "            image = image.resize((config['image_size'], config['image_size']), Image.BICUBIC)\n",
        "\n",
        "        image = np.array(image)\n",
        "        if self.cache:\n",
        "            self.image_cache[path] = image\n",
        "        return image\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        image = self._load_image(path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHKvjisn53wj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pathlib import Path\n",
        "\n",
        "def split_image_dataset(data_dir, test_size=0.2, valid_extensions=('.jpg', '.jpeg', '.png')):\n",
        "    samples = []\n",
        "    labels = []\n",
        "\n",
        "    for class_dir in Path(data_dir).iterdir():\n",
        "        if not class_dir.is_dir():\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            label = int(class_dir.name)\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "        for img_file in class_dir.glob('*'):\n",
        "            if img_file.suffix.lower() in valid_extensions:\n",
        "                samples.append((str(img_file), label))\n",
        "                labels.append(label)\n",
        "\n",
        "\n",
        "    train_samples, val_samples = train_test_split(\n",
        "        samples,\n",
        "        test_size=test_size,\n",
        "        stratify=labels\n",
        "    )\n",
        "\n",
        "    return train_samples, val_samples\n",
        "\n",
        "train_samples, val_samples = split_image_dataset(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFZ9y0EWxhqO"
      },
      "outputs": [],
      "source": [
        "\n",
        "config = {\n",
        "    'batch_size': 128,\n",
        "    'num_workers': 2,\n",
        "    'lr': 0.001,\n",
        "    'epochs': 5,\n",
        "    'patience': 3,\n",
        "    'warmup_epochs': 1,\n",
        "    'image_size': 64\n",
        "}\n",
        "\n",
        "basic_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.3),\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "advanced_transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.3),\n",
        "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=10, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.3),\n",
        "    A.Normalize(mean=mean, std=std),\n",
        "    ToTensorV2(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVoqXoux4aft"
      },
      "outputs": [],
      "source": [
        "train_basic = AdvancedDataset(train_samples, transform=basic_transform)\n",
        "train_advanced = AdvancedDataset(train_samples, transform=advanced_transform)\n",
        "train_tl = AdvancedDataset(train_samples, transform=advanced_transform, upscale=True)\n",
        "\n",
        "val_ds = AdvancedDataset(val_samples, transform=basic_transform)\n",
        "val_tl = AdvancedDataset(val_samples, transform=basic_transform, upscale=True)\n",
        "\n",
        "\n",
        "train_basic_loader = DataLoader(train_basic, batch_size=config['batch_size'], shuffle=True, num_workers=config['num_workers'])\n",
        "train_advanced_loader = DataLoader(train_advanced, batch_size=config['batch_size'], shuffle=True, num_workers=config['num_workers'])\n",
        "train_tl_loader = DataLoader(train_tl, batch_size=config['batch_size'], shuffle=True, num_workers=config['num_workers'])\n",
        "\n",
        "val_loader = DataLoader(val_ds, batch_size=config['batch_size'], shuffle=False, num_workers=config['num_workers'])\n",
        "val_tl_loader = DataLoader(val_tl, batch_size=config['batch_size'], shuffle=False, num_workers=config['num_workers'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ceMIL3D3bRX"
      },
      "outputs": [],
      "source": [
        "class BasicCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128 * 4 * 4, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "def create_resnet(num_classes, pretrained=True):\n",
        "    model = models.resnet18(pretrained=pretrained)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    return model\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, config, model_name):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=config['lr'])\n",
        "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2, factor=0.5)\n",
        "\n",
        "    best_acc = 0.0\n",
        "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
        "\n",
        "    for epoch in range(config['epochs']):\n",
        "        print(f\"\\nEpoch {epoch+1}/{config['epochs']} - {model_name}\")\n",
        "\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for inputs, labels in tqdm(train_loader, desc=\"Training\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        train_loss = running_loss / len(train_loader)\n",
        "        train_acc = 100. * correct / total\n",
        "\n",
        "\n",
        "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
        "        print(f\"Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(model.state_dict(), f\"best_{model_name}.pth\")\n",
        "\n",
        "    plot_history(history, model_name)\n",
        "    return model, history\n",
        "\n",
        "def validate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    val_loss = running_loss / len(val_loader)\n",
        "    val_acc = 100. * correct / total\n",
        "    return val_loss, val_acc\n",
        "\n",
        "def plot_history(history, title):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['train_loss'], label='Train Loss')\n",
        "    plt.plot(history['val_loss'], label='Val Loss')\n",
        "    plt.title(f'{title} - Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['train_acc'], label='Train Acc')\n",
        "    plt.plot(history['val_acc'], label='Val Acc')\n",
        "    plt.title(f'{title} - Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AbqpnwIuo-7"
      },
      "source": [
        "# **Базовая CNN с базовыми аугментациями**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vat5pX7AqPJ"
      },
      "outputs": [],
      "source": [
        "results = {}\n",
        "model = BasicCNN(num_classes)\n",
        "history = train_model(model, train_basic_loader, val_loader,config,\"BasicCNN_basic_aug\")\n",
        "results['BasicCNN_basic_aug'] = history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHXolqlku_3c"
      },
      "source": [
        "# **2. Базовая CNN с продвинутыми аугментациями**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uv8Ws1XXF6Ve",
        "outputId": "2a14a5d3-4249-45f0-b29e-9a298357434e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/5 - BasicCNN_advanced_aug\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 60/60 [00:37<00:00,  1.60it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 4.4553 | Val Loss: 4.1254\n",
            "Train Acc: 3.92% | Val Acc: 8.46%\n",
            "\n",
            "Epoch 2/5 - BasicCNN_advanced_aug\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  33%|███▎      | 20/60 [00:12<00:21,  1.82it/s]"
          ]
        }
      ],
      "source": [
        "model = BasicCNN(num_classes)\n",
        "history = train_model(model, train_advanced_loader, val_loader,config, \"BasicCNN_advanced_aug\")\n",
        "results['BasicCNN_advanced_aug'] = history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWD_8ybTvN8X"
      },
      "source": [
        "# **3. ResNet с апскейлингом и базовыми аугментациями**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by0j4wAkGLA6"
      },
      "outputs": [],
      "source": [
        "model = create_resnet(num_classes)\n",
        "history = train_model(model, train_basic_loader, val_tl_loader, config, \"ResNet_basic_aug\")\n",
        "results['ResNet_basic_aug'] = history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oXrrHLsvSz5"
      },
      "source": [
        "# **4. ResNet с апскейлингом и продвинутыми аугментациями (скор на кагле)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mPLl6HE-BysX"
      },
      "outputs": [],
      "source": [
        "model_4 = create_resnet(num_classes)\n",
        "history = train_model(model_4, train_tl_loader, val_tl_loader, config, \"ResNet_advanced_aug\")\n",
        "results['ResNet_advanced_aug'] = history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emSFm1YLNHdq"
      },
      "outputs": [],
      "source": [
        "class TestDataset(Dataset):\n",
        "    def __init__(self, test_dir, transform):\n",
        "        self.paths = sorted([\n",
        "            os.path.join(test_dir, fname)\n",
        "            for fname in os.listdir(test_dir)\n",
        "            if fname.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "        ])\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.paths[idx]\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                img = img.convert(\"RGB\")\n",
        "                img = np.array(img)\n",
        "                img = self.transform(image=img)[\"image\"]\n",
        "            return img, os.path.basename(img_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            dummy_img = torch.zeros(3, *self.transform.size, dtype=torch.float32)\n",
        "            return dummy_img, os.path.basename(img_path)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "test_dataset = TestDataset(test_dir=test_dir, transform=test_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymSZ5KNuJZZs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHmruAkbT9MZ"
      },
      "outputs": [],
      "source": [
        "model = results['ResNet_advanced_aug'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7FvahwCtUrVr"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(\"best_ResNet_advanced_aug.pth\"))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for images, filenames in tqdm(test_loader):\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = outputs.max(1)\n",
        "        for fname, label in zip(filenames, predicted.cpu().numpy()):\n",
        "            img_id = int(os.path.splitext(fname)[0])\n",
        "            predictions.append((img_id, label))\n",
        "\n",
        "\n",
        "predictions.sort(key=lambda x: x[0])\n",
        "\n",
        "df = pd.DataFrame(predictions, columns=[\"id\", \"target\"])\n",
        "df.to_csv(\"submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tpHTunuVVcT"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8HJFLp0dgmi"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}